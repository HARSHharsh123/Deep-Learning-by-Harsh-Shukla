{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e053191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f175bdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[8,8,4],[7,9,5],[6,10,6],[5,12,7]], columns=['cgpa', 'profile_score', 'lpa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbf465e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>profile_score</th>\n",
       "      <th>lpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cgpa  profile_score  lpa\n",
       "0     8              8    4\n",
       "1     7              9    5\n",
       "2     6             10    6\n",
       "3     5             12    7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e46bdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    ## making dictionary for initializing the values of weights and bias (w = 0.1 and b = 0)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims) ## this length helps to iterate the loop\n",
    "    for l in range(1 , L):\n",
    "        ## very simple interpretation of finding weights and bias \n",
    "        \n",
    "        parameters['W' + str(l)] = np.ones((layer_dims[l-1] , layer_dims[l])) * 0.1\n",
    "        \n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l] , 1))\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1562bce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.1, 0.1],\n",
       "        [0.1, 0.1]]),\n",
       " 'b1': array([[0.],\n",
       "        [0.]]),\n",
       " 'W2': array([[0.1],\n",
       "        [0.1]]),\n",
       " 'b2': array([[0.]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_parameters([2,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "036eebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A_prev, W, b):\n",
    "  \n",
    "  Z = np.dot(W.T, A_prev) + b\n",
    "  \n",
    "  return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31dd3bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Prop\n",
    "\n",
    "def L_layer_forward(X, parameters):\n",
    "    A = X\n",
    "    for l in range(1,3):\n",
    "        A_prev = A \n",
    "        Wl = parameters['W' + str(l)]\n",
    "        bl = parameters['b' + str(l)]\n",
    "#         print(\"A\"+str(l-1)+\": \", A_prev)\n",
    "#         print(\"W\"+str(l)+\": \", Wl)\n",
    "#         print(\"b\"+str(l)+\": \", bl)\n",
    "#         print(\"--\"*20)\n",
    "\n",
    "        A = linear_forward(A_prev, Wl, bl)\n",
    "#         print(\"A\"+str(l)+\": \", A)\n",
    "#         print(\"**\"*20)\n",
    "    return A,A_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e52f7769",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['cgpa' , 'profile_score']].values[0].reshape(2,1)\n",
    "y = df[['lpa']].values[0][0]\n",
    "parameters = initialize_parameters([2,2,1])\n",
    "y_hat , A1 = L_layer_forward(X, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f833ecb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = y_hat[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ddf3a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters,y,y_hat,A1,X):\n",
    "    parameters['W2'][0][0] = parameters['W2'][0][0] + (0.001 * 2 * (y - y_hat)*A1[0][0])\n",
    "    parameters['W2'][1][0] = parameters['W2'][1][0] + (0.001 * 2 * (y - y_hat)*A1[1][0])\n",
    "    parameters['b2'][0][0] = parameters['W2'][1][0] + (0.001 * 2 * (y - y_hat))\n",
    "    \n",
    "    parameters['W1'][0][0] = parameters['W1'][0][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][0][0]*X[0][0])\n",
    "    parameters['W1'][0][1] = parameters['W1'][0][1] + (0.001 * 2 * (y - y_hat)*parameters['W2'][0][0]*X[1][0])\n",
    "    parameters['b1'][0][0] = parameters['b1'][0][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][0][0])\n",
    "\n",
    "    parameters['W1'][1][0] = parameters['W1'][1][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][1][0]*X[0][0])\n",
    "    parameters['W1'][1][1] = parameters['W1'][1][1] + (0.001 * 2 * (y - y_hat)*parameters['W2'][1][0]*X[1][0])\n",
    "    parameters['b1'][1][0] = parameters['b1'][1][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36acadd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_parameters(parameters,y,y_hat,A1,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4041be02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.10658137, 0.10658137],\n",
       "        [0.10658137, 0.10658137]]),\n",
       " 'b1': array([[0.00082267],\n",
       "        [0.00082267]]),\n",
       " 'W2': array([[0.111776],\n",
       "        [0.111776]]),\n",
       " 'b2': array([[0.119136]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters ## for first student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af628f9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch -  1 Loss -  25.321744156025517\n",
      "Epoch -  2 Loss -  18.320004165722047\n",
      "Epoch -  3 Loss -  9.473661050729625\n",
      "Epoch -  4 Loss -  3.252093863403161\n",
      "Epoch -  5 Loss -  1.3407132589299964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.26507636, 0.38558861],\n",
       "        [0.27800387, 0.40980287]]),\n",
       " 'b1': array([[0.02749056],\n",
       "        [0.02974394]]),\n",
       " 'W2': array([[0.41165744],\n",
       "        [0.48302736]]),\n",
       " 'b2': array([[0.48646246]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epochs implementation\n",
    "\n",
    "parameters = initialize_parameters([2,2,1])\n",
    "epochs = 5\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "  Loss = []\n",
    "\n",
    "  for j in range(df.shape[0]):\n",
    "\n",
    "    X = df[['cgpa', 'profile_score']].values[j].reshape(2,1) # Shape(no of features, no. of training example)\n",
    "    y = df[['lpa']].values[j][0]\n",
    "\n",
    "    # Parameter initialization\n",
    "\n",
    "\n",
    "    y_hat,A1 = L_layer_forward(X,parameters)\n",
    "    y_hat = y_hat[0][0]\n",
    "\n",
    "    update_parameters(parameters,y,y_hat,A1,X)\n",
    "\n",
    "    Loss.append((y-y_hat)**2)\n",
    "\n",
    "  print('Epoch - ',i+1,'Loss - ',np.array(Loss).mean())\n",
    "\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9856c3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.15.0-cp39-cp39-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.15.0\n",
      "  Downloading tensorflow_intel-2.15.0-cp39-cp39-win_amd64.whl (300.8 MB)\n",
      "     ------------------------------------ 300.8/300.8 MB 427.2 kB/s eta 0:00:00\n",
      "Collecting ml-dtypes~=0.2.0\n",
      "  Downloading ml_dtypes-0.2.0-cp39-cp39-win_amd64.whl (938 kB)\n",
      "     ------------------------------------ 938.4/938.4 kB 259.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (63.4.1)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "     ------------------------------------ 442.0/442.0 kB 282.0 kB/s eta 0:00:00\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     -------------------------------------- 65.5/65.5 kB 708.3 kB/s eta 0:00:00\n",
      "Collecting tensorboard<2.16,>=2.15\n",
      "  Downloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "     ---------------------------------------- 5.5/5.5 MB 614.4 kB/s eta 0:00:00\n",
      "Collecting flatbuffers>=23.5.26\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting keras<2.16,>=2.15.0\n",
      "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "     -------------------------------------- 130.2/130.2 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.7.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "     -------------------------------------- 24.4/24.4 MB 688.6 kB/s eta 0:00:00\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.60.0-cp39-cp39-win_amd64.whl (3.7 MB)\n",
      "     ---------------------------------------- 3.7/3.7 MB 778.6 kB/s eta 0:00:00\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 656.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hs081\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\hs081\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.4)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.25.1-cp39-cp39-win_amd64.whl (413 kB)\n",
      "     -------------------------------------- 413.4/413.4 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.5/57.5 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.37.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.23.4-cp39-cp39-win_amd64.whl (422 kB)\n",
      "     -------------------------------------- 422.5/422.5 kB 1.6 MB/s eta 0:00:00\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.26.1-py2.py3-none-any.whl (186 kB)\n",
      "     -------------------------------------- 186.4/186.4 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting google-auth-oauthlib<2,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.28.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.15.0->tensorflow) (3.0.9)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     ------------------------------------ 151.7/151.7 kB 645.9 kB/s eta 0:00:00\n",
      "Installing collected packages: libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, protobuf, opt-einsum, oauthlib, ml-dtypes, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.0.0 astunparse-1.6.3 cachetools-5.3.2 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.26.1 google-auth-oauthlib-1.2.0 google-pasta-0.2.0 grpcio-1.60.0 keras-2.15.0 libclang-16.0.6 ml-dtypes-0.2.0 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.23.4 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.15.1 tensorboard-data-server-0.7.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-intel-2.15.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts pyrsa-decrypt.exe, pyrsa-encrypt.exe, pyrsa-keygen.exe, pyrsa-priv2pub.exe, pyrsa-sign.exe and pyrsa-verify.exe are installed in 'C:\\Users\\hs081\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script google-oauthlib-tool.exe is installed in 'C:\\Users\\hs081\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\hs081\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts estimator_ckpt_converter.exe, import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\hs081\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7c93d11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tensor Flow implementation of Backpropagation \n",
    "\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "885a1fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(2 , activation = 'linear' , input_dim = 2))\n",
    "model.add(Dense(1 , activation = 'linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f0e1ba79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9 (36.00 Byte)\n",
      "Trainable params: 9 (36.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1de9d046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.8309468,  0.0783056],\n",
       "        [ 1.0192655, -0.1881231]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[-0.45405877],\n",
       "        [-1.3485808 ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## keras randomly assigns the weights \n",
    "\n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "edb00bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## but we have to assign the weights according to our implementation \n",
    "\n",
    "new_weights = [ np.array([[0.1 , 0.1] , \n",
    "                         [0.1 , 0.1]] , dtype = np.float32),\n",
    "              np.array([0. , 0.] , dtype = np.float32) , \n",
    "              np.array([[0.1] , \n",
    "                       [0.1]] , dtype = np.float32), \n",
    "              np.array([0.] , dtype = np.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1db31177",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b9138d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.1, 0.1],\n",
       "        [0.1, 0.1]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[0.1],\n",
       "        [0.1]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "afe6f178",
   "metadata": {},
   "outputs": [],
   "source": [
    "## assigning the value of learning rate = 0.001\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7e66eb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compilation step \n",
    "\n",
    "model.compile(loss= 'mse' , optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "860be662",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "4/4 [==============================] - 1s 5ms/step - loss: 27.8873\n",
      "Epoch 2/70\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 27.5830\n",
      "Epoch 3/70\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 27.2296\n",
      "Epoch 4/70\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 26.9070\n",
      "Epoch 5/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 26.5653\n",
      "Epoch 6/70\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 26.1874\n",
      "Epoch 7/70\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 25.8133\n",
      "Epoch 8/70\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 25.4408\n",
      "Epoch 9/70\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 25.0780\n",
      "Epoch 10/70\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 24.6410\n",
      "Epoch 11/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 24.2445\n",
      "Epoch 12/70\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 23.7892\n",
      "Epoch 13/70\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 23.3930\n",
      "Epoch 14/70\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 22.9384\n",
      "Epoch 15/70\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 22.4748\n",
      "Epoch 16/70\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 22.0285\n",
      "Epoch 17/70\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 21.4992\n",
      "Epoch 18/70\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 21.0883\n",
      "Epoch 19/70\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 20.5490\n",
      "Epoch 20/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 20.0745\n",
      "Epoch 21/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 19.5533\n",
      "Epoch 22/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 19.0553\n",
      "Epoch 23/70\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 18.5218\n",
      "Epoch 24/70\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 18.0419\n",
      "Epoch 25/70\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.4877\n",
      "Epoch 26/70\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.9780\n",
      "Epoch 27/70\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.4575\n",
      "Epoch 28/70\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 15.9068\n",
      "Epoch 29/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 15.4135\n",
      "Epoch 30/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 14.9223\n",
      "Epoch 31/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 14.3612\n",
      "Epoch 32/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 13.8178\n",
      "Epoch 33/70\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.3436\n",
      "Epoch 34/70\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 12.7734\n",
      "Epoch 35/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 12.2559\n",
      "Epoch 36/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 11.7879\n",
      "Epoch 37/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 11.3295\n",
      "Epoch 38/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 10.7788\n",
      "Epoch 39/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 10.3516\n",
      "Epoch 40/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 9.8717\n",
      "Epoch 41/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 9.3852\n",
      "Epoch 42/70\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.9595\n",
      "Epoch 43/70\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 8.5606\n",
      "Epoch 44/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 8.0743\n",
      "Epoch 45/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 7.7386\n",
      "Epoch 46/70\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 7.2770\n",
      "Epoch 47/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.9544\n",
      "Epoch 48/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.4901\n",
      "Epoch 49/70\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 6.2032\n",
      "Epoch 50/70\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.8141\n",
      "Epoch 51/70\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.5159\n",
      "Epoch 52/70\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.2178\n",
      "Epoch 53/70\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.9012\n",
      "Epoch 54/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.6240\n",
      "Epoch 55/70\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.3317\n",
      "Epoch 56/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.1164\n",
      "Epoch 57/70\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.8259\n",
      "Epoch 58/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.6312\n",
      "Epoch 59/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.4021\n",
      "Epoch 60/70\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.1983\n",
      "Epoch 61/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.0082\n",
      "Epoch 62/70\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.8532\n",
      "Epoch 63/70\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.6605\n",
      "Epoch 64/70\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.5156\n",
      "Epoch 65/70\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.3907\n",
      "Epoch 66/70\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.2723\n",
      "Epoch 67/70\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.1531\n",
      "Epoch 68/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.0398\n",
      "Epoch 69/70\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.9427\n",
      "Epoch 70/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.8379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x205dfd52ac0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(df.iloc[:,:-1].values, df.iloc[:,-1].values , verbose = 1 , epochs = 70 , batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f91ac1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
